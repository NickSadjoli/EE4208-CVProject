{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from utils import *\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently listed people in database: \n",
      "==> adam\n",
      "==> andreea\n",
      "==> carla\n",
      "==> colin\n",
      "==> dan\n",
      "==> dennis\n",
      "==> derek\n",
      "==> derrick_nospec\n",
      "==> eric\n",
      "==> graham\n",
      "==> heather\n",
      "==> kate\n",
      "==> katherine\n",
      "==> keith\n",
      "==> nicholas\n",
      "==> nicholas_two\n",
      "==> ntjy\n",
      "==> paul\n",
      "==> richard\n",
      "==> sarah\n",
      "==> sean\n",
      "==> tasos\n",
      "==> tom\n",
      "==> yogesh\n",
      "==> yongmin\n",
      "current path ./database/adam. Counter = 0\n",
      "current path ./database/andreea. Counter = 1\n",
      "current path ./database/carla. Counter = 2\n",
      "current path ./database/colin. Counter = 3\n",
      "current path ./database/dan. Counter = 4\n",
      "current path ./database/dennis. Counter = 5\n",
      "current path ./database/derek. Counter = 6\n",
      "current path ./database/derrick_nospec. Counter = 7\n",
      "current path ./database/eric. Counter = 8\n",
      "current path ./database/graham. Counter = 9\n",
      "current path ./database/heather. Counter = 10\n",
      "current path ./database/kate. Counter = 11\n",
      "current path ./database/katherine. Counter = 12\n",
      "current path ./database/keith. Counter = 13\n",
      "current path ./database/nicholas. Counter = 14\n",
      "current path ./database/nicholas_two. Counter = 15\n",
      "current path ./database/ntjy. Counter = 16\n",
      "current path ./database/paul. Counter = 17\n",
      "current path ./database/richard. Counter = 18\n",
      "current path ./database/sarah. Counter = 19\n",
      "current path ./database/sean. Counter = 20\n",
      "current path ./database/tasos. Counter = 21\n",
      "current path ./database/tom. Counter = 22\n",
      "current path ./database/yogesh. Counter = 23\n",
      "current path ./database/yongmin. Counter = 24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[178, 184, 181, ..., 200, 139, 165],\n",
       "       [176, 181, 182, ..., 210, 139, 157],\n",
       "       [179, 195, 180, ..., 202, 147, 169],\n",
       "       ...,\n",
       "       [182, 180, 179, ..., 214, 152, 167],\n",
       "       [178, 177, 178, ..., 207, 153, 164],\n",
       "       [188, 161, 113, ..., 210, 157, 165]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = database_to_table(\"./database/\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicholas_sadjoli/.virtualenvs/ee4208_assign_2/local/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#standardised dataset\n",
    "data_std = StandardScaler().fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate mean face\n",
    "mean = np.mean(data,axis=0)\n",
    "mean_std = np.mean(data_std,axis=0)\n",
    "np.savetxt(\"average_face_test_ii.csv\", mean, delimiter=\",\")\n",
    "cv2.imwrite(\"average_face_test_ii.jpg\", np.array(np.reshape(mean, (100,100))) )\n",
    "np.savetxt(\"average_face_test_ii_std.csv\", mean_std, delimiter=\",\")\n",
    "cv2.imwrite(\"average_face_test_ii_std.jpg\", np.array(np.reshape(mean_std, (100,100))) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 10000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_deduct = data - mean\n",
    "mean_deduct_std = data_std - mean_std\n",
    "mean_deduct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2960.80645161 3072.57419355 3045.12741935 ...  685.49032258\n",
      "  1697.92580645 2206.42258065]\n",
      " [3072.57419355 3402.92103226 3417.58735484 ...  672.21445161\n",
      "  1765.75412903 2304.50077419]\n",
      " [3045.12741935 3417.58735484 3578.63974194 ...  657.60780645\n",
      "  1795.21006452 2313.08374194]\n",
      " ...\n",
      " [ 685.49032258  672.21445161  657.60780645 ... 1145.81135484\n",
      "   976.10232258 1092.25406452]\n",
      " [1697.92580645 1765.75412903 1795.21006452 ...  976.10232258\n",
      "  1702.04490323 1942.27858065]\n",
      " [2206.42258065 2304.50077419 2313.08374194 ... 1092.25406452\n",
      "  1942.27858065 2502.5996129 ]]\n",
      "[[1.00806452 0.97579764 0.94303931 ... 0.37516998 0.76245905 0.8171021 ]\n",
      " [0.97579764 1.00806452 0.98724064 ... 0.34317345 0.73961739 0.7960559 ]\n",
      " [0.94303931 0.98724064 1.00806452 ... 0.32737065 0.73326188 0.77915705]\n",
      " ...\n",
      " [0.37516998 0.34317345 0.32737065 ... 1.00806452 0.70459832 0.65021914]\n",
      " [0.76245905 0.73961739 0.73326188 ... 0.70459832 1.00806452 0.94867762]\n",
      " [0.8171021  0.7960559  0.77915705 ... 0.65021914 0.94867762 1.00806452]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#default_covariance\n",
    "cov = mean_deduct.T.dot(mean_deduct)/(mean_deduct.shape[0] - 1)\n",
    "cov_std = mean_deduct_std.T.dot(mean_deduct_std)/(mean_deduct_std.shape[0] - 1)\n",
    "print cov\n",
    "print cov_std\n",
    "np.shape(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2960.80645161 3072.57419355 3045.12741935 ...  685.49032258\n",
      "  1697.92580645 2206.42258065]\n",
      " [3072.57419355 3402.92103226 3417.58735484 ...  672.21445161\n",
      "  1765.75412903 2304.50077419]\n",
      " [3045.12741935 3417.58735484 3578.63974194 ...  657.60780645\n",
      "  1795.21006452 2313.08374194]\n",
      " ...\n",
      " [ 685.49032258  672.21445161  657.60780645 ... 1145.81135484\n",
      "   976.10232258 1092.25406452]\n",
      " [1697.92580645 1765.75412903 1795.21006452 ...  976.10232258\n",
      "  1702.04490323 1942.27858065]\n",
      " [2206.42258065 2304.50077419 2313.08374194 ... 1092.25406452\n",
      "  1942.27858065 2502.5996129 ]]\n",
      "[[1.00806452 0.97579764 0.94303931 ... 0.37516998 0.76245905 0.8171021 ]\n",
      " [0.97579764 1.00806452 0.98724064 ... 0.34317345 0.73961739 0.7960559 ]\n",
      " [0.94303931 0.98724064 1.00806452 ... 0.32737065 0.73326188 0.77915705]\n",
      " ...\n",
      " [0.37516998 0.34317345 0.32737065 ... 1.00806452 0.70459832 0.65021914]\n",
      " [0.76245905 0.73961739 0.73326188 ... 0.70459832 1.00806452 0.94867762]\n",
      " [0.8171021  0.7960559  0.77915705 ... 0.65021914 0.94867762 1.00806452]]\n"
     ]
    }
   ],
   "source": [
    "#numpy's covariance\n",
    "cov_np = np.cov(mean_deduct.T)\n",
    "cov_np_std = np.cov(mean_deduct_std.T)\n",
    "print cov_np\n",
    "print cov_np_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_val, eig_vect = np.linalg.eig(cov)\n",
    "eig_val_std, eig_vect_std = np.linalg.eig(cov_std)\n",
    "print np.shape(eig_val), np.shape(eig_vect), np.shape(eig_val_std), np.shape(eig_vect_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(eig_vect)):\n",
    "    print i, np.testing.assert_array_almost_equal(1.0, np.linalg.norm(eig_vect[:,i])), np.shape(eig_vect[:,i]),  np.testing.assert_array_almost_equal(1.0, np.linalg.norm(eig_vect_std[:,i])), np.shape(eig_vect_std[:,i])\n",
    "print (\"Every eigenvector is confirmed to have length of about 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_pairs = [(np.abs(eig_val[i]), eig_vect[:,i]) for i in range (len(eig_val))]\n",
    "eigen_pairs_std = [(np.abs(eig_val_std[i]), eig_vect_std[:,i]) for i in range (len(eig_val_std))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(eigen_pairs)):\n",
    "    print eigen_pairs[k][0], eigen_pairs_std[k][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note that you can specify a function as the key so that sorted() can sort based on your specified function. \n",
    "#in this case, eigen pair is sorted based on the value of the eigenvalue\n",
    "eigen_pair_sorted = sorted(eigen_pairs, key=lambda pair:pair[0])\n",
    "eigen_pair_sorted_std =  sorted(eigen_pairs_std, key=lambda pair:pair[0])\n",
    "print eigen_pair_sorted[0], eigen_pair_sorted[9999], eigen_pair_sorted_std[0], eigen_pair_sorted_std[9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_pair_sorted.reverse()\n",
    "eigen_pair_sorted_std.reverse()\n",
    "print eigen_pair_sorted[0], eigen_pair_sorted[9999], eigen_pair_sorted_std[0], eigen_pair_sorted_std[9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, pair in enumerate(eigen_pair_sorted):\n",
    "    print count, pair[0]\n",
    "for count, pair in enumerate(eigen_pair_sorted_std):\n",
    "    print count, pair[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "temp_std = []\n",
    "counter = 0\n",
    "counter_std = 0\n",
    "for pair in eigen_pair_sorted:\n",
    "    if counter == 125:\n",
    "        break\n",
    "    temp.append(np.real(pair[1]))\n",
    "    counter += 1\n",
    "    \n",
    "for pair_std in eigen_pair_sorted_std:\n",
    "    if counter_std == 125:\n",
    "        break\n",
    "    temp_std.append(np.real(pair_std[1]))\n",
    "    counter_std += 1\n",
    "    \n",
    "eig_vect_sorted = np.array(temp).T\n",
    "eig_vect_sorted_std = np.array(temp_std).T\n",
    "print eig_vect_sorted, np.shape(eig_vect_sorted), \n",
    "print eig_vect_sorted_std, np.shape(eig_vect_sorted_std)\n",
    "np.savetxt(\"eigenvector_nptest.csv\", eig_vect_sorted, delimiter=\",\")\n",
    "np.savetxt(\"eigenvector_nptest_std.csv\", eig_vect_sorted_std, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vect_scaled = np.copy(eig_vect_sorted) * 255\n",
    "np.savetxt(\"eigenvector_nptest_scaled.csv\", eig_vect_scaled, delimiter=\",\")\n",
    "eig_vect_normalized = np.copy(eig_vect_sorted)\n",
    "for i in range(0,10000):\n",
    "    eig_vect_normalized[i] = eig_vect_normalized[i] / np.linalg.norm(eig_vect_normalized[i])\n",
    "np.savetxt(\"eigenvector_nptest_normalized.csv\", eig_vect_normalized, delimiter=\",\")\n",
    "eig_vect_normalized_scaled = np.copy(eig_vect_normalized) * 255\n",
    "np.savetxt(\"eigenvector_nptest_normalized_scaled.csv\", eig_vect_normalized_scaled, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0,10):\n",
    "    cv2.imwrite(\"eigenfaces_test_\"+str(j)+\".jpg\", np.reshape(eig_vect_sorted[:,j], (100,100)) )\n",
    "    cv2.imwrite(\"eigenfaces_test_std_\"+str(j)+\".jpg\", np.reshape(eig_vect_sorted_std[:,j], (100,100)) )\n",
    "    cv2.imwrite(\"eigenfaces_test_scaled_\"+str(j)+\".jpg\", np.reshape(eig_vect_scaled[:,j],(100,100)) ) \n",
    "    cv2.imwrite(\"eigenfaces_test_normalized_\"+str(j)+\".jpg\", np.reshape(eig_vect_normalized[:,j], (100,100)) )\n",
    "    cv2.imwrite(\"eigenfaces_test_normalized_scaled\"+str(j)+\".jpg\", np.reshape(eig_vect_normalized_scaled[:,j], (100,100)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = mean_deduct.dot(eig_vect_sorted)\n",
    "reduced_std = mean_deduct_std.dot(eig_vect_sorted_std)\n",
    "reduced_scaled = mean_deduct.dot(eig_vect_scaled)\n",
    "reduced_normalized = mean_deduct.dot(eig_vect_normalized)\n",
    "reduced_normalized_scaled = mean_deduct.dot(eig_vect_normalized_scaled)\n",
    "print np.shape(reduced)\n",
    "np.savetxt(\"reduced_test_plotlyguide.csv\", reduced, delimiter=\",\")\n",
    "np.savetxt(\"reduced_test_plotlyguide_std.csv\", reduced_std, delimiter=\",\")\n",
    "np.savetxt(\"reduced_test_plotlyguide_scaled.csv\", reduced_scaled, delimiter=\",\")\n",
    "np.savetxt(\"reduced_test_plotlyguide_norm.csv\", reduced_normalized, delimiter=\",\")\n",
    "np.savetxt(\"reduced_test_plotlyguide_norm_scaled.csv\", reduced_normalized_scaled, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
